import os
import ast
import pandas as pd
from sqlalchemy import create_engine, Column, String, DateTime, Text, Integer, ForeignKey
from sqlalchemy.orm import declarative_base, sessionmaker

# Get database URL from environment, default to data/articles.db
DATABASE_URL = os.getenv('DATABASE_URL', 'sqlite:///data/articles.db')

# Create engine
engine = create_engine(DATABASE_URL)
Base = declarative_base()

# Define the Publishers table
class Publisher(Base):
    __tablename__ = 'publishers'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    name = Column(String, unique=True)

# Define the Authors table
class Author(Base):
    __tablename__ = 'authors'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    name = Column(String, unique=True)

# Define the Articles table
class Article(Base):
    __tablename__ = 'articles'
    
    id = Column(String, primary_key=True)
    headline = Column(String)
    pub_date = Column(DateTime)
    auth_id = Column(Integer, ForeignKey('authors.id'))
    pub_id = Column(Integer, ForeignKey('publishers.id'))
    section_name = Column(String)
    subsection = Column(String)
    body = Column(Text)
    web_url = Column(String)

def normalize_byline(byline_value):
    """Ensure byline data is a dict with a 'person' list."""
    if isinstance(byline_value, str):
        try:
            byline_value = ast.literal_eval(byline_value)
        except Exception:
            return {'person': []}
    if isinstance(byline_value, dict):
        return byline_value
    if isinstance(byline_value, list):
        return {'person': byline_value}
    return {'person': []}


def extract_person(byline_value):
    if isinstance(byline_value, dict):
        return byline_value.get('person', [])
    if isinstance(byline_value, list):
        return byline_value
    return []


def proper_case(name_part):
    if not isinstance(name_part, str):
        return ''
    return name_part.title() if name_part.isupper() else name_part


def first_person_name(person_list):
    if person_list:
        person = person_list[0]
        firstname = proper_case(person.get('firstname', '').strip())
        lastname = proper_case(person.get('lastname', '').strip())
        return f"{firstname} {lastname}".strip()
    return ''

def load_articles_to_db():
    """Load articles from CSV into the database"""
    
    # Read CSV with required columns
    csv_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'articles.csv')
    df = pd.read_csv(csv_path)
    
    # Select only the required columns
    required_columns = ['pub_date', 'source', 'section_name', 'headline', 'subsection_name', 'body', 'web_url', 'byline']
    df = df[required_columns]

    # Clean up data - replace NaN with None
    df = df.where(pd.notna(df), None)

    # Normalize and extract author info
    df['byline'] = df['byline'].apply(normalize_byline)
    df['person'] = df['byline'].apply(extract_person)
    df['author'] = df['person'].apply(first_person_name)

    # Convert pub_date to datetime
    df['pub_date'] = pd.to_datetime(df['pub_date'], errors='coerce')
    
    # Drop all existing tables and create them fresh
    Base.metadata.drop_all(engine)
    Base.metadata.create_all(engine)
    
    # Insert data into database
    Session = sessionmaker(bind=engine)
    session = Session()
    
    try:
        # Get or create publishers
        publishers_map = {}
        for source in df['source'].unique():
            if source is not None:
                pub = session.query(Publisher).filter_by(name=source).first()
                if not pub:
                    pub = Publisher(name=source)
                    session.add(pub)
                    session.flush()
                publishers_map[source] = pub.id
        
        # Get or create authors
        authors_map = {}
        for author in df['author'].unique():
            if author is not None and author.strip():
                auth = session.query(Author).filter_by(name=author).first()
                if not auth:
                    auth = Author(name=author)
                    session.add(auth)
                    session.flush()
                authors_map[author] = auth.id
        
        # Insert articles with foreign keys
        for idx, row in df.iterrows():
            pub_id = publishers_map.get(row['source'])
            auth_id = authors_map.get(row['author'])
            
            article = Article(
                id=str(idx),
                pub_date=row['pub_date'],
                pub_id=pub_id,
                section_name=row['section_name'],
                headline=row['headline'],
                subsection=row['subsection_name'],
                body=row['body'],
                web_url=row['web_url'],
                auth_id=auth_id
            )
            session.add(article)
        
        session.commit()
        print(f"Successfully loaded {len(df)} articles into the database")
        print(f"Added {len(publishers_map)} publishers and {len(authors_map)} authors")
        
    except Exception as e:
        session.rollback()
        print(f"Error loading articles: {e}")
        raise
    finally:
        session.close()

if __name__ == '__main__':
    load_articles_to_db()
